{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efbfac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/hackathon-example-policies\n"
     ]
    }
   ],
   "source": [
    "%cd hackathon-example-policies/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a99e9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from example_policies import lerobot_patches\n",
    "lerobot_patches.apply_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "246bb107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "\n",
    "EPISODE_PATH = \"20250916_083723\"\n",
    "# TODO: Set the path to your converted dataset directory.\n",
    "DATA_DIR = pathlib.Path(f\"conversion_test/{EPISODE_PATH}_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b25b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-09-16 10:38:11 ils/utils.py:48 Cuda backend detected, using cuda.\n",
      "WARNING 2025-09-16 10:38:11 /policies.py:79 Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training Configuration (full details):\n",
      "TrainPipelineConfig(dataset=DatasetConfig(repo_id='20250916_083723_output',\n",
      "                                          root=PosixPath('conversion_test/20250916_083723_output'),\n",
      "                                          episodes=[0, 1, 4],\n",
      "                                          image_transforms=ImageTransformsConfig(enable=False,\n",
      "                                                                                 max_num_transforms=3,\n",
      "                                                                                 random_order=False,\n",
      "                                                                                 tfs={'brightness': ImageTransformConfig(weight=1.0,\n",
      "                                                                                                                         type='ColorJitter',\n",
      "                                                                                                                         kwargs={'brightness': (0.8,\n",
      "                                                                                                                                                1.2)}),\n",
      "                                                                                      'contrast': ImageTransformConfig(weight=1.0,\n",
      "                                                                                                                       type='ColorJitter',\n",
      "                                                                                                                       kwargs={'contrast': (0.8,\n",
      "                                                                                                                                            1.2)}),\n",
      "                                                                                      'hue': ImageTransformConfig(weight=1.0,\n",
      "                                                                                                                  type='ColorJitter',\n",
      "                                                                                                                  kwargs={'hue': (-0.05,\n",
      "                                                                                                                                  0.05)}),\n",
      "                                                                                      'saturation': ImageTransformConfig(weight=1.0,\n",
      "                                                                                                                         type='ColorJitter',\n",
      "                                                                                                                         kwargs={'saturation': (0.5,\n",
      "                                                                                                                                                1.5)}),\n",
      "                                                                                      'sharpness': ImageTransformConfig(weight=1.0,\n",
      "                                                                                                                        type='SharpnessJitter',\n",
      "                                                                                                                        kwargs={'sharpness': (0.5,\n",
      "                                                                                                                                              1.5)})}),\n",
      "                                          revision=None,\n",
      "                                          use_imagenet_stats=True,\n",
      "                                          video_backend='torchcodec'),\n",
      "                    env=None,\n",
      "                    policy=SO3ACTConfig(n_obs_steps=1,\n",
      "                                        normalization_mapping={'ACTION': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                                               'STATE': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                                               'VISUAL': <NormalizationMode.MEAN_STD: 'MEAN_STD'>},\n",
      "                                        input_features={},\n",
      "                                        output_features={},\n",
      "                                        device='cuda',\n",
      "                                        use_amp=False,\n",
      "                                        push_to_hub=False,\n",
      "                                        repo_id=None,\n",
      "                                        private=None,\n",
      "                                        tags=None,\n",
      "                                        license=None,\n",
      "                                        chunk_size=30,\n",
      "                                        n_action_steps=30,\n",
      "                                        vision_backbone='resnet34',\n",
      "                                        pretrained_backbone_weights='ResNet34_Weights.IMAGENET1K_V1',\n",
      "                                        replace_final_stride_with_dilation=False,\n",
      "                                        pre_norm=False,\n",
      "                                        dim_model=512,\n",
      "                                        n_heads=8,\n",
      "                                        dim_feedforward=3200,\n",
      "                                        feedforward_activation='relu',\n",
      "                                        n_encoder_layers=4,\n",
      "                                        n_decoder_layers=7,\n",
      "                                        use_vae=True,\n",
      "                                        latent_dim=64,\n",
      "                                        n_vae_encoder_layers=4,\n",
      "                                        temporal_ensemble_coeff=None,\n",
      "                                        dropout=0.1,\n",
      "                                        kl_weight=10.0,\n",
      "                                        optimizer_lr=2e-05,\n",
      "                                        optimizer_weight_decay=0.0001,\n",
      "                                        optimizer_lr_backbone=2e-05),\n",
      "                    output_dir=None,\n",
      "                    job_name=None,\n",
      "                    resume=False,\n",
      "                    seed=1000,\n",
      "                    num_workers=4,\n",
      "                    batch_size=24,\n",
      "                    steps=800000,\n",
      "                    eval_freq=20000,\n",
      "                    log_freq=200,\n",
      "                    save_checkpoint=True,\n",
      "                    save_freq=10000,\n",
      "                    use_policy_training_preset=True,\n",
      "                    optimizer=None,\n",
      "                    scheduler=None,\n",
      "                    eval=EvalConfig(n_episodes=50,\n",
      "                                    batch_size=50,\n",
      "                                    use_async_envs=False),\n",
      "                    wandb=WandBConfig(enable=True,\n",
      "                                      disable_artifact=True,\n",
      "                                      project='lerobot',\n",
      "                                      entity=None,\n",
      "                                      notes=None,\n",
      "                                      run_id=None,\n",
      "                                      mode=None))\n"
     ]
    }
   ],
   "source": [
    "from example_policies.config_factory import act_config, diffusion_config, smolvla_config\n",
    "\n",
    "cfg = act_config(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "208266f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.wandb.enable = False\n",
    "cfg.steps = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c664a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-09-16 10:41:02 ts/train.py:111 {'batch_size': 24,\n",
      " 'dataset': {'episodes': [0, 1, 4],\n",
      "             'image_transforms': {'enable': False,\n",
      "                                  'max_num_transforms': 3,\n",
      "                                  'random_order': False,\n",
      "                                  'tfs': {'brightness': {'kwargs': {'brightness': [0.8,\n",
      "                                                                                   1.2]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'contrast': {'kwargs': {'contrast': [0.8,\n",
      "                                                                               1.2]},\n",
      "                                                       'type': 'ColorJitter',\n",
      "                                                       'weight': 1.0},\n",
      "                                          'hue': {'kwargs': {'hue': [-0.05,\n",
      "                                                                     0.05]},\n",
      "                                                  'type': 'ColorJitter',\n",
      "                                                  'weight': 1.0},\n",
      "                                          'saturation': {'kwargs': {'saturation': [0.5,\n",
      "                                                                                   1.5]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'sharpness': {'kwargs': {'sharpness': [0.5,\n",
      "                                                                                 1.5]},\n",
      "                                                        'type': 'SharpnessJitter',\n",
      "                                                        'weight': 1.0}}},\n",
      "             'repo_id': '20250916_083723_output',\n",
      "             'revision': None,\n",
      "             'root': 'conversion_test/20250916_083723_output',\n",
      "             'use_imagenet_stats': True,\n",
      "             'video_backend': 'torchcodec'},\n",
      " 'env': None,\n",
      " 'eval': {'batch_size': 50, 'n_episodes': 50, 'use_async_envs': False},\n",
      " 'eval_freq': 20000,\n",
      " 'job_name': 'integrated_so3_act',\n",
      " 'log_freq': 200,\n",
      " 'num_workers': 4,\n",
      " 'optimizer': {'betas': [0.9, 0.999],\n",
      "               'eps': 1e-08,\n",
      "               'grad_clip_norm': 10.0,\n",
      "               'lr': 2e-05,\n",
      "               'type': 'adamw',\n",
      "               'weight_decay': 0.0001},\n",
      " 'output_dir': 'outputs/train/2025-09-16/10-38-21_integrated_so3_act',\n",
      " 'policy': {'chunk_size': 30,\n",
      "            'device': 'cuda',\n",
      "            'dim_feedforward': 3200,\n",
      "            'dim_model': 512,\n",
      "            'dropout': 0.1,\n",
      "            'feedforward_activation': 'relu',\n",
      "            'input_features': {'observation.images.rgb_left': {'shape': [3,\n",
      "                                                                         640,\n",
      "                                                                         640],\n",
      "                                                               'type': <FeatureType.VISUAL: 'VISUAL'>},\n",
      "                               'observation.images.rgb_right': {'shape': [3,\n",
      "                                                                          640,\n",
      "                                                                          640],\n",
      "                                                                'type': <FeatureType.VISUAL: 'VISUAL'>},\n",
      "                               'observation.images.rgb_static': {'shape': [3,\n",
      "                                                                           640,\n",
      "                                                                           640],\n",
      "                                                                 'type': <FeatureType.VISUAL: 'VISUAL'>},\n",
      "                               'observation.state': {'shape': [32],\n",
      "                                                     'type': <FeatureType.STATE: 'STATE'>}},\n",
      "            'kl_weight': 10.0,\n",
      "            'latent_dim': 64,\n",
      "            'license': None,\n",
      "            'n_action_steps': 30,\n",
      "            'n_decoder_layers': 7,\n",
      "            'n_encoder_layers': 4,\n",
      "            'n_heads': 8,\n",
      "            'n_obs_steps': 1,\n",
      "            'n_vae_encoder_layers': 4,\n",
      "            'normalization_mapping': {'ACTION': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                      'STATE': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                      'VISUAL': <NormalizationMode.MEAN_STD: 'MEAN_STD'>},\n",
      "            'optimizer_lr': 2e-05,\n",
      "            'optimizer_lr_backbone': 2e-05,\n",
      "            'optimizer_weight_decay': 0.0001,\n",
      "            'output_features': {'action': {'shape': [14],\n",
      "                                           'type': <FeatureType.ACTION: 'ACTION'>}},\n",
      "            'pre_norm': False,\n",
      "            'pretrained_backbone_weights': 'ResNet34_Weights.IMAGENET1K_V1',\n",
      "            'private': None,\n",
      "            'push_to_hub': False,\n",
      "            'replace_final_stride_with_dilation': False,\n",
      "            'repo_id': None,\n",
      "            'tags': None,\n",
      "            'temporal_ensemble_coeff': None,\n",
      "            'type': 'integrated_so3_act',\n",
      "            'use_amp': False,\n",
      "            'use_vae': True,\n",
      "            'vision_backbone': 'resnet34'},\n",
      " 'resume': False,\n",
      " 'save_checkpoint': True,\n",
      " 'save_freq': 10000,\n",
      " 'scheduler': None,\n",
      " 'seed': 1000,\n",
      " 'steps': 2000,\n",
      " 'use_policy_training_preset': True,\n",
      " 'wandb': {'disable_artifact': True,\n",
      "           'enable': False,\n",
      "           'entity': None,\n",
      "           'mode': None,\n",
      "           'notes': None,\n",
      "           'project': 'lerobot',\n",
      "           'run_id': None}}\n",
      "INFO 2025-09-16 10:41:02 ts/train.py:117 \u001b[1m\u001b[33mLogs will be saved locally.\u001b[0m\n",
      "INFO 2025-09-16 10:41:02 ts/train.py:127 Creating dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-09-16 10:41:02 ts/train.py:138 Creating policy\n",
      "INFO 2025-09-16 10:41:04 ts/train.py:144 Creating optimizer and scheduler\n",
      "INFO 2025-09-16 10:41:04 ts/train.py:156 \u001b[1m\u001b[33mOutput dir:\u001b[0m outputs/train/2025-09-16/10-38-21_integrated_so3_act\n",
      "INFO 2025-09-16 10:41:04 ts/train.py:159 cfg.steps=2000 (2K)\n",
      "INFO 2025-09-16 10:41:04 ts/train.py:160 dataset.num_frames=624 (624)\n",
      "INFO 2025-09-16 10:41:04 ts/train.py:161 dataset.num_episodes=3\n",
      "INFO 2025-09-16 10:41:04 ts/train.py:162 num_learnable_params=94055118 (94M)\n",
      "INFO 2025-09-16 10:41:04 ts/train.py:163 num_total_params=94055256 (94M)\n",
      "INFO 2025-09-16 10:41:04 ts/train.py:202 Start offline training on a fixed dataset\n",
      "INFO 2025-09-16 10:42:43 ts/train.py:232 step:200 smpl:5K ep:23 epch:7.69 loss:70.004 grdn:2190.550 lr:2.0e-05 updt_s:0.453 data_s:0.043\n",
      "INFO 2025-09-16 10:44:23 ts/train.py:232 step:400 smpl:10K ep:46 epch:15.38 loss:33.077 grdn:592.938 lr:2.0e-05 updt_s:0.452 data_s:0.045\n",
      "INFO 2025-09-16 10:47:41 ts/train.py:232 step:800 smpl:19K ep:92 epch:30.77 loss:29.536 grdn:406.166 lr:2.0e-05 updt_s:0.452 data_s:0.037\n",
      "INFO 2025-09-16 10:49:20 ts/train.py:232 step:1K smpl:24K ep:115 epch:38.46 loss:28.802 grdn:366.183 lr:2.0e-05 updt_s:0.452 data_s:0.043\n",
      "INFO 2025-09-16 10:50:59 ts/train.py:232 step:1K smpl:29K ep:138 epch:46.15 loss:27.550 grdn:353.314 lr:2.0e-05 updt_s:0.451 data_s:0.042\n",
      "INFO 2025-09-16 10:52:37 ts/train.py:232 step:1K smpl:34K ep:162 epch:53.85 loss:23.498 grdn:397.014 lr:2.0e-05 updt_s:0.452 data_s:0.038\n",
      "INFO 2025-09-16 10:54:17 ts/train.py:232 step:2K smpl:38K ep:185 epch:61.54 loss:20.659 grdn:394.550 lr:2.0e-05 updt_s:0.451 data_s:0.043\n",
      "INFO 2025-09-16 10:55:56 ts/train.py:232 step:2K smpl:43K ep:208 epch:69.23 loss:18.475 grdn:337.535 lr:2.0e-05 updt_s:0.452 data_s:0.044\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from example_policies.train import train\n",
    "\n",
    "train(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls outputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57bfff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
