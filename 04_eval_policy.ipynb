{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa93b9d1",
   "metadata": {},
   "source": [
    "# 🚀 Deploy a Trained Policy\n",
    "\n",
    "This notebook guides you through deploying a trained policy to a physical robot. \n",
    "\n",
    "### Process:\n",
    "1.  **Configure**: Set the path to your trained model and the robot's server address.\n",
    "2.  **Load**: The `policy_loader` automatically loads the model and its training configuration.\n",
    "3.  **Deploy**: The `deploy_policy` function starts the inference loop and sends commands to the robot.\n",
    "\n",
    "The deployment script automatically handles details like the action space (`tcp`, `joint`, etc.) based on the loaded training configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99212cf-80be-4f11-bbdb-f6b351177db4",
   "metadata": {},
   "source": [
    "# 0. Add additional helpers for the dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba73a88-bebc-49df-a2e6-2da1e07e26fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7341b8e-351e-4e0e-8ef1-7364c7643daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limitations under the License.\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import grpc\n",
    "\n",
    "# Lerobot Environment Bug\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from example_policies.robot_deploy.action_translator import ActionMode, ActionTranslator\n",
    "from example_policies.robot_deploy.debug_helpers.utils import print_info\n",
    "from example_policies.robot_deploy.policy_loader import load_policy\n",
    "from example_policies.robot_deploy.robot_io.robot_interface import RobotInterface\n",
    "from example_policies.robot_deploy.robot_io.robot_service import (\n",
    "    robot_service_pb2,\n",
    "    robot_service_pb2_grpc,\n",
    ")\n",
    "\n",
    "TIME_TO_GET_INTO_STARTING_POSITION_S = 3\n",
    "\n",
    "\n",
    "def set_tcp_position(service_stub, cfg, position: list[float]):\n",
    "    pos = torch.tensor(position).unsqueeze(0)\n",
    "    \n",
    "    robot_interface = RobotInterface(service_stub, cfg)\n",
    "    robot_interface.send_action(position, ActionMode.ABS_TCP)\n",
    "\n",
    "\n",
    "def inference_loop(\n",
    "    policy, cfg, hz: float, service_stub: robot_service_pb2_grpc.RobotServiceStub, observation_callback_fn=None, steps=None,\n",
    "    starting_position=None\n",
    "):\n",
    "    robot_interface = RobotInterface(service_stub, cfg)\n",
    "    model_to_action_trans = ActionTranslator(cfg)\n",
    "\n",
    "    step = 0\n",
    "    done = False\n",
    "\n",
    "    if starting_position is not None:\n",
    "        print(\"Starting position provided, moving the robot to the starting position\")\n",
    "        set_tcp_position(service_stub, cfg, starting_position)\n",
    "        time.sleep(TIME_TO_GET_INTO_STARTING_POSITION_S)\n",
    "        print(\"Wait to get into the position finished\")\n",
    "        # TODO (could actually fetch a position and compare).\n",
    "    \n",
    "    # Inference Loop\n",
    "    print(\"Starting inference loop...\")\n",
    "    period = 1.0 / hz\n",
    "\n",
    "    while not done and (steps is None or step < steps):\n",
    "        start_time = time.time()\n",
    "        # print(policy.config.input_features)\n",
    "        print(\"Step:\", step)\n",
    "        observation = robot_interface.get_observation(cfg.device, show=False)\n",
    "\n",
    "        if observation:\n",
    "            if observation_callback_fn:\n",
    "                observation_callback_fn(observation)\n",
    "            # Predict the next action with respect to the current observation\n",
    "            with torch.inference_mode():\n",
    "                action = policy.select_action(observation)\n",
    "                # print(f\"\\n=== RAW MODEL PREDICTION ===\")\n",
    "                # print_info(step, observation, action)\n",
    "                # print()\n",
    "            action = model_to_action_trans.translate(action, observation)\n",
    "\n",
    "            # print(f\"\\n=== ABSOLUTE ROBOT COMMANDS ===\")\n",
    "            # print_info(step, observation, action)\n",
    "            robot_interface.send_action(action, model_to_action_trans.action_mode)\n",
    "            # policy._queues[\"action\"].clear()\n",
    "\n",
    "        # wait for execution to finish\n",
    "        elapsed_time = time.time() - start_time\n",
    "        sleep_duration = period - elapsed_time\n",
    "        # print(sleep_duration)\n",
    "        # wait for input\n",
    "        # input(\"Press Enter to continue...\")\n",
    "        time.sleep(max(0.0, sleep_duration))\n",
    "\n",
    "        step += 1\n",
    "\n",
    "\n",
    "def deploy_policy(policy, cfg, hz: float, server: str, observation_callback_fn=None, steps=100, starting_position=None):\n",
    "    channel = grpc.insecure_channel(server)\n",
    "    stub = robot_service_pb2_grpc.RobotServiceStub(channel)\n",
    "    try:\n",
    "        inference_loop(policy, cfg, hz, stub, observation_callback_fn, steps, starting_position)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        raise e\n",
    "    finally:\n",
    "        channel.close()\n",
    "        print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0eb7c79-37d5-49bd-ae19-aa4ea244d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "import time\n",
    "\n",
    "BLUE_BOX_TASK_DESCRIPTION = 'Put the white cube in the blue container'\n",
    "\n",
    "class Recorder:\n",
    "    def __init__(self, output_dir, task_description_default=None):\n",
    "        self.rgb_left_frames = []\n",
    "        self.rgb_right_frames = []\n",
    "        self.rgb_static_frames = []\n",
    "        self.output_dir = output_dir\n",
    "        self.episode_n = 0\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.task_description_default = task_description_default\n",
    "        \n",
    "    def process_obs(self, obs):\n",
    "        if 'task' not in obs and self.task_description_default is not None:\n",
    "            obs['task'] = [self.task_description_default]\n",
    "    \n",
    "        frame_rgb_right = process_frame(obs['observation.images.rgb_right'])\n",
    "        frame_rgb_left = process_frame(obs['observation.images.rgb_left'])\n",
    "        frame_rgb_static = process_frame(obs['observation.images.rgb_static'])\n",
    "        self.rgb_right_frames.append(frame_rgb_right)\n",
    "        self.rgb_left_frames.append(frame_rgb_left)\n",
    "        self.rgb_static_frames.append(frame_rgb_static)\n",
    "\n",
    "    def save_and_start_new(self):\n",
    "        imageio.mimsave(f\"{self.output_dir}/eval_episode_{self.episode_n}_right.mp4\", np.stack(self.rgb_right_frames), fps=INFERENCE_FREQUENCY_HZ)\n",
    "        imageio.mimsave(f\"{self.output_dir}/eval_episode_{self.episode_n}_left.mp4\", np.stack(self.rgb_left_frames), fps=INFERENCE_FREQUENCY_HZ)\n",
    "        imageio.mimsave(f\"{self.output_dir}/eval_episode_{self.episode_n}_static.mp4\", np.stack(self.rgb_static_frames), fps=INFERENCE_FREQUENCY_HZ)\n",
    "\n",
    "        self.rgb_left_frames = []\n",
    "        self.rgb_right_frames = []\n",
    "        self.rgb_static_frames = []\n",
    "        self.episode_n +=1\n",
    "\n",
    "        \n",
    "def process_frame(frame):\n",
    "    return (frame.cpu().squeeze().transpose(0, 2) * 255).to(torch.uint8)\n",
    "\n",
    "\n",
    "def eval_policy(policy, cfg, hz, server, output_dir, starting_position=None, num_episodes=10, steps_per_episode=100, time_to_reset_env_s=10, task_description_default=BLUE_BOX_TASK_DESCRIPTION):\n",
    "\n",
    "    recorder = Recorder(output_dir=output_dir, task_description_default=task_description_default)\n",
    "\n",
    "    for episode_n in range(num_episodes):\n",
    "        print(f\"Starting episode {episode_n}\")\n",
    "        \n",
    "        try:\n",
    "            deploy_policy(policy, cfg, hz=INFERENCE_FREQUENCY_HZ, server=SERVER_ENDPOINT, observation_callback_fn=recorder.process_obs, steps=steps_per_episode, starting_position=starting_position)\n",
    "        except Exception as e:\n",
    "            print(\"oh no\", e, e.__traceback__)\n",
    "            print(e)\n",
    "            raise(e)\n",
    "        print(f\"Saving videos for episode {episode_n}\")\n",
    "        recorder.save_and_start_new()\n",
    "        print(\"Reset environment before the next episode\")\n",
    "        time.sleep(time_to_reset_env_s)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596978f",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "First, specify the necessary parameters for deployment. **You must edit these values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8d6840b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load policy from: /home/jovyan/hackathon-example-policies/notebooks/outputs/train/2025-09-18/19-59-18_smolvla\n",
      "Robot server endpoint: 192.168.0.212:50051\n",
      "Inference frequency: 10.0 Hz\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# TODO: Change to the directory containing your trained policy checkpoint.\n",
    "# Example: \"outputs/2025-09-14/12-00-00\"\n",
    "CHECKPOINT_DIR = pathlib.Path(\"/home/jovyan/hackathon-example-policies/notebooks/outputs/train/2025-09-18/19-59-18_smolvla/\")\n",
    "\n",
    "# TODO: Change to the robot's IP address.\n",
    "SERVER_ENDPOINT = \"192.168.0.212:50051\"\n",
    "\n",
    "# Inference frequency in Hz. Higher values result in smoother but potentially faster movements.\n",
    "INFERENCE_FREQUENCY_HZ: float = 10.0\n",
    "\n",
    "print(f\"Attempting to load policy from: {CHECKPOINT_DIR}\")\n",
    "print(f\"Robot server endpoint: {SERVER_ENDPOINT}\")\n",
    "print(f\"Inference frequency: {INFERENCE_FREQUENCY_HZ} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2219ec5-71c9-4dc4-a8a3-eb500560fd98",
   "metadata": {},
   "source": [
    "## 1.5 Configuration for the HOME position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f78064c9-60b3-433d-b547-0b325b500a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = [-0.2108,  0.6804,  0.4403, -0.0931,  0.9910,  0.0301,  0.0914,  0.1795,\n",
    "         0.6926,  0.4007, -0.0163, -0.9996, -0.0122,  0.0170]\n",
    "\n",
    "\n",
    "def get_current_tcp_position(service_stub, cfg):\n",
    "    robot_interface = RobotInterface(service_stub, cfg)\n",
    "    snapshot_response, robot_names = robot_interface.client.get_snapshot()\n",
    "\n",
    "    tcp_state = robot_interface.observation_builder._get_tcp_state(snapshot_response, robot_names)\n",
    "    return tcp_state\n",
    "\n",
    "\n",
    "def set_in_home():\n",
    "    set_tcp_position(stub, cfg, HOME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b08c8-d737-4ae7-9ffb-91e23ba3f799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb1da41f-a080-4136-be33-8c6b599dc283",
   "metadata": {},
   "source": [
    "To configure the new HOME position, set the robot in the desired position and run the following code (after uncommenting the HOME =...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a65bc327-fc73-4d6d-8999-fa786cd8d85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1969,  0.6755,  0.4361, -0.0694,  0.9929,  0.0246,  0.0938,  0.1647,\n",
      "         0.6868,  0.3982, -0.0248, -0.9995, -0.0072,  0.0171])\n"
     ]
    }
   ],
   "source": [
    "channel = grpc.insecure_channel(SERVER_ENDPOINT)\n",
    "stub = robot_service_pb2_grpc.RobotServiceStub(channel)\n",
    "pos = get_current_tcp_position(stub, cfg)\n",
    "\n",
    "print(torch.tensor(pos))\n",
    "\n",
    "# Uncomment the function to set the new home position.\n",
    "# HOME = pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6129b",
   "metadata": {},
   "source": [
    "## 2. Load the Policy\n",
    "\n",
    "Now, we load the policy from the specified checkpoint directory. The loader will find the latest checkpoint and its corresponding configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "855477b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path /home/jovyan/hackathon-example-policies/notebooks/outputs/train/2025-09-18/19-59-18_smolvla does not contain config.json, extending path.\n",
      "Reducing the number of VLM layers to 16 ...\n",
      "Loading weights from local directory\n",
      "✅ Policy loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from example_policies.robot_deploy import policy_loader\n",
    "\n",
    "policy, cfg = policy_loader.load_policy(CHECKPOINT_DIR)\n",
    "\n",
    "print(\"✅ Policy loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3740f5",
   "metadata": {},
   "source": [
    "## 3. (Optional) Modify Policy Attributes\n",
    "\n",
    "Before deployment, you can override policy attributes for experimentation. For example, you might want to adjust the action chunking (`n_action_steps`) to see how it affects robot behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6808129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and modify the lines below to change policy attributes.\n",
    "# For available options, refer to the lerobot policy's config documentation.\n",
    "\n",
    "# policy.device = \"cuda\"  # or \"cpu\"\n",
    "# policy.n_action_steps = 15  # Number of actions to predict in each forward pass\n",
    "\n",
    "# print(f\"Policy will run on device: {policy.device}\")\n",
    "# print(f\"Action steps set to: {policy.n_action_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10fa971",
   "metadata": {},
   "source": [
    "## 4. Eval policy on the robot\n",
    "\n",
    "Finally, execute the cell below to start sending commands to the robot.\n",
    "\n",
    "⚠️ **Warning**: This will move the physical robot. Ensure the robot has a clear and safe workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3efed5b-0a33-42bd-88fb-bf5d664ef22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode 0\n",
      "Starting position provided, moving the robot to the starting position\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54805/2434847504.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos = torch.tensor(position).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait to get into the position finished\n",
      "Starting inference loop...\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Connection closed.\n",
      "Saving videos for episode 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment before the next episode\n",
      "Starting episode 1\n",
      "Starting position provided, moving the robot to the starting position\n",
      "Wait to get into the position finished\n",
      "Starting inference loop...\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Connection closed.\n",
      "Saving videos for episode 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment before the next episode\n",
      "Starting episode 2\n",
      "Starting position provided, moving the robot to the starting position\n",
      "Wait to get into the position finished\n",
      "Starting inference loop...\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Connection closed.\n",
      "Saving videos for episode 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment before the next episode\n",
      "Starting episode 3\n",
      "Starting position provided, moving the robot to the starting position\n",
      "Wait to get into the position finished\n",
      "Starting inference loop...\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Connection closed.\n",
      "Saving videos for episode 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment before the next episode\n",
      "Starting episode 4\n",
      "Starting position provided, moving the robot to the starting position\n",
      "Wait to get into the position finished\n",
      "Starting inference loop...\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Connection closed.\n",
      "Saving videos for episode 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment before the next episode\n",
      "Starting episode 5\n",
      "Starting position provided, moving the robot to the starting position\n",
      "Wait to get into the position finished\n",
      "Starting inference loop...\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Connection closed.\n",
      "Saving videos for episode 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment before the next episode\n",
      "Starting episode 6\n",
      "Starting position provided, moving the robot to the starting position\n",
      "Wait to get into the position finished\n",
      "Starting inference loop...\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Connection closed.\n",
      "Saving videos for episode 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment before the next episode\n",
      "Starting episode 7\n",
      "Starting position provided, moving the robot to the starting position\n",
      "Wait to get into the position finished\n",
      "Starting inference loop...\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Connection closed.\n",
      "Saving videos for episode 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment before the next episode\n",
      "Starting episode 8\n",
      "Starting position provided, moving the robot to the starting position\n",
      "Wait to get into the position finished\n",
      "Starting inference loop...\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Connection closed.\n",
      "Saving videos for episode 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment before the next episode\n",
      "Starting episode 9\n",
      "Starting position provided, moving the robot to the starting position\n",
      "Wait to get into the position finished\n",
      "Starting inference loop...\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Connection closed.\n",
      "Saving videos for episode 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment before the next episode\n"
     ]
    }
   ],
   "source": [
    "STEPS_PER_EPISODE = 10\n",
    "OUTPUT_DIR = \"eval/eval1/\"\n",
    "STARTING_POSITION = torch.tensor(HOME)\n",
    "NUM_EPISODES = 10\n",
    "eval_policy(policy, cfg, hz=INFERENCE_FREQUENCY_HZ, server=SERVER_ENDPOINT, steps_per_episode=STEPS_PER_EPISODE, output_dir=OUTPUT_DIR, \n",
    "            starting_position=STARTING_POSITION, num_episodes=NUM_EPISODES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639acc23-32eb-4a30-9f24-c83869f1c26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee76a8f8-eb7f-4af5-8a94-97d4d1535b22",
   "metadata": {},
   "source": [
    "## 5. Videos from eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1cf5b89e-cb72-4f11-9316-ee610d258fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation videos for the episode: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_0_right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_0_left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_0_static.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation videos for the episode: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_1_right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_1_left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_1_static.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation videos for the episode: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_2_right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_2_left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_2_static.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation videos for the episode: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_3_right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_3_left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_3_static.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation videos for the episode: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_4_right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_4_left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_4_static.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation videos for the episode: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_5_right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_5_left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_5_static.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation videos for the episode: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_6_right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_6_left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_6_static.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation videos for the episode: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_7_right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_7_left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_7_static.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation videos for the episode: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_8_right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_8_left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_8_static.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation videos for the episode: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_9_right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_9_left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"eval/eval1//eval_episode_9_static.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "    print(f\"Evaluation videos for the episode: {episode}\")\n",
    "    display(Video(f\"{OUTPUT_DIR}/eval_episode_{episode}_right.mp4\"))\n",
    "    display(Video(f\"{OUTPUT_DIR}/eval_episode_{episode}_left.mp4\"))\n",
    "    display(Video(f\"{OUTPUT_DIR}/eval_episode_{episode}_static.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4baa3ba-0ca4-44da-8c67-f0aa15a694c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
